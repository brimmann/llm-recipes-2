{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b9cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brimmann/works/llm-recipes-2/models/checkpoint_handler.py:7: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead\n",
      "  import torch.distributed._shard.checkpoint as dist_cp\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from models.modeling_xgemma import XGemmaForCausalLM, XGemmaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd415616",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = XGemmaConfig(\n",
    "    vocab_size=256000,  # Gemma-2 uses 256k vocabulary\n",
    "    hidden_size=2048,   # Hidden size for 1B model\n",
    "    intermediate_size=16384,  # FFN intermediate size\n",
    "    num_hidden_layers=18,  # Number of transformer layers\n",
    "    num_attention_heads=8,  # Number of attention heads\n",
    "    num_key_value_heads=1,  # GQA: number of key-value heads\n",
    "    head_dim=256,  # Dimension per attention head\n",
    "    max_position_embeddings=8192,  # Context length\n",
    "    rms_norm_eps=1e-6,\n",
    "    rope_theta=10000.0,\n",
    "    attention_bias=False,\n",
    "    attention_dropout=0.0,\n",
    "    # Custom XGemma parameters\n",
    "    projector_type='mlp2x_gelu',\n",
    "    retriever_hidden_size=4096,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc43192",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7861b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGemmaForCausalLM(config)\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00706718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): GELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): GemmaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       "  (projector): Projector(\n",
       "    (projector): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16824f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_xrag_token_id(256000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97646551",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "    'input_ids': torch.tensor([[\n",
    "        733, 16289, 28793, 24316, 28747, 32001, 28725, 690, 835, 2825,\n",
    "        28747, 28792, 28748, 16289, 28793, 415, 2990, 302, 9143, 403,\n",
    "        16783, 23799, 356, 4117, 28705, 28740, 28787, 28725, 28705, 28740,\n",
    "        28787, 28750, 28750, 28725, 304, 403, 10806, 1987, 9143, 8897\n",
    "    ]]).to(device),\n",
    "    'attention_mask': torch.ones(1, 40).to(device),  # Simplified for example\n",
    "    'retrieval_embeds': torch.randn(1, 128).to(device),  # Random retrieval embedding\n",
    "    'labels': torch.tensor([[\n",
    "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
    "        -100, -100, -100, -100, -100, 415, 2990, 302, 9143, 403,\n",
    "        16783, 23799, 356, 4117, 28705, 28740, 28787, 28725, 28705, 28740,\n",
    "        28787, 28750, 28750, 28725, 304, 403, 10806, 1987, 9143, 8897\n",
    "    ]]).to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(\n",
    "        input_ids=batch['input_ids'],\n",
    "        attention_mask=batch['attention_mask'],\n",
    "        retrieval_embeds=batch['retrieval_embeds'],\n",
    "        labels=batch['labels'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9713b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.datasets import dataset as DatasetConfig\n",
    "from configs.training import train_config as TrainConfig\n",
    "from configs.distillation import distillation_config as DistillationConfig\n",
    "from configs.fsdp import fsdp_config as FsdpConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80ca6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = DatasetConfig()\n",
    "train_config = TrainConfig()\n",
    "distill_config = DistillationConfig()\n",
    "fsdp_config = DistillationConfig()\n",
    "train_config.model_name = \"google/gemma-3-1b-it\"\n",
    "distill_config.model_name = \"Hannibal046/xrag-7b\"\n",
    "train_config.batch_size_training = 1\n",
    "train_config.num_workers_dataloader = 1\n",
    "dataset_config.file = \"data/loaders/squad-v2-sampled.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1940edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "xgemma_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e0706d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgemma_tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<xRAG>\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a97be149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(256001, 2048, padding_idx=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(xgemma_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "363f6982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Training Set Length = 1000\n",
      "--> Validation Set Length = 250\n"
     ]
    }
   ],
   "source": [
    "from data.data_utils import get_dataloader\n",
    "student_train_dataloader, student_eval_dataloader = get_dataloader(dataset_config, train_config, xgemma_tokenizer, 0, distill_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2653ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter1 = iter(student_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "468dbb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = next(iter1)\n",
    "# item = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30d3a2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   106,   1645,    108,   7266, 235292, 235248, 256000, 235269,    948,\n",
       "           1170,   3454, 235292,    107, 235274, 235265,  45029,    840,  98615,\n",
       "            109, 235284, 235265,  11976,  98615,    109, 235304, 235265,  76759,\n",
       "           1706,    109, 235310, 235265,  76759,  11827,    109, 235308, 235265,\n",
       "          76759,   6181,    109, 235318, 235265,  76759,  12776,    109, 235324,\n",
       "         235265,  76759,  46002,    109, 235321, 235265,  76759,  51625,    109,\n",
       "         235315, 235265,  76759,  19967,    109, 235274, 235276, 235265,  76759,\n",
       "         113061,    109, 235274, 235274, 235265,  76759,   5368,    109, 235274,\n",
       "         235284, 235265,  76759, 127403,    109, 235274, 235304, 235265,  76759,\n",
       "           5239,    109, 235274, 235310, 235265,  76759,  22241,    109, 235274,\n",
       "         235308, 235265,  76759,  46002,    604,  38823,    109, 235274, 235318,\n",
       "         235265,  76759,  46002,    604,  61348,    109, 235274, 235324, 235265,\n",
       "          76759,  46002,    604,  65396,    109, 235274, 235321, 235265,  76759,\n",
       "          46002,    604, 165026,    109, 235274, 235315, 235265,  76759,  46002,\n",
       "            604, 103806,    109, 235284, 235276, 235265,  76759,  46002,    604,\n",
       "          65396,    109, 235284, 235274, 235265,  76759,  46002,    604, 165026,\n",
       "            109, 235284, 235284, 235265,   2742]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1]]), 'retrieval_embeds': tensor([[ 3.5312, -4.6562,  1.0156,  ...,  3.1094, -2.4375, -1.0156]]), 'labels': tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100, 235274, 235265,  45029,    840,  98615,\n",
       "            109, 235284, 235265,  11976,  98615,    109, 235304, 235265,  76759,\n",
       "           1706,    109, 235310, 235265,  76759,  11827,    109, 235308, 235265,\n",
       "          76759,   6181,    109, 235318, 235265,  76759,  12776,    109, 235324,\n",
       "         235265,  76759,  46002,    109, 235321, 235265,  76759,  51625,    109,\n",
       "         235315, 235265,  76759,  19967,    109, 235274, 235276, 235265,  76759,\n",
       "         113061,    109, 235274, 235274, 235265,  76759,   5368,    109, 235274,\n",
       "         235284, 235265,  76759, 127403,    109, 235274, 235304, 235265,  76759,\n",
       "           5239,    109, 235274, 235310, 235265,  76759,  22241,    109, 235274,\n",
       "         235308, 235265,  76759,  46002,    604,  38823,    109, 235274, 235318,\n",
       "         235265,  76759,  46002,    604,  61348,    109, 235274, 235324, 235265,\n",
       "          76759,  46002,    604,  65396,    109, 235274, 235321, 235265,  76759,\n",
       "          46002,    604, 165026,    109, 235274, 235315, 235265,  76759,  46002,\n",
       "            604, 103806,    109, 235284, 235276, 235265,  76759,  46002,    604,\n",
       "          65396,    109, 235284, 235274, 235265,  76759,  46002,    604, 165026,\n",
       "            109, 235284, 235284, 235265,   2742]])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e621e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start_of_turn>user\\nBackground: <xRAG>, which also means:<end_of_turn>Internet service provider'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgemma_tokenizer.decode(item['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c8f77e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[256000]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgemma_tokenizer.convert_tokens_to_ids([\"<xRAG>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b165e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item['retrieval_embeds'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d4a408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=item['input_ids'].to(device)\n",
    "attention_mask=item['attention_mask'].to(device)\n",
    "retrieval_embeds=item['retrieval_embeds'].to(device)\n",
    "labels=item['labels'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "108356f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e03edd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        retrieval_embeds=retrieval_embeds,\n",
    "        labels=labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1e4ea6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.8053, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b97b13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 149, 256001])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
