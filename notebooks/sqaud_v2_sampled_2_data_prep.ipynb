{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/brimmann/llm-recipes-2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/llm-recipes-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"datasets==3.6\" \"transformers>=4.57.1\" \"sentencepiece==0.2.1\" \"wandb>=0.22.2\" \"peft==0.9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"brimmann2/squad-v2-sampled2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6505b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt.prompt import create_chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_column(item, tokenizer):\n",
    "    item['prompt'] = create_chat_prompt(\n",
    "                \"qa\", 0,\n",
    "                title = \"\",\n",
    "                context = item['context'],\n",
    "                question = item['question'],\n",
    "                sys_user = True,\n",
    "                chat_template = tokenizer.apply_chat_template\n",
    "            )\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "tokenizer.add_special_tokens({\"pad_token\":tokenizer.eos_token})\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds = ds.map(lambda item: create_prompt_column(item, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55edb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06107053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(items, tokenizer):\n",
    "    return tokenizer(items[\"prompt\"], padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdb4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnds = nds.map(lambda items: tokenization(items, tokenizer=tokenizer), batched=True, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854804be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb65185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(nnds, batch_size=8, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ced05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105beee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d63b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            output = model.generate(\n",
    "                batch['input_ids'].to(device),\n",
    "                attention_mask=batch['attention_mask'].to(device),\n",
    "                max_new_tokens=150,\n",
    "                do_sample=False,\n",
    "                eos_token_id= tokenizer.eos_token_id\n",
    "            )\n",
    "            output = output[:, len(batch['input_ids'][0]):]\n",
    "            sentences = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "            for i in range(len(sentences)):\n",
    "                sentences[i] = sentences[i].split('\\n')[0].strip()\n",
    "            predictions.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704dc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0eac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generated = Dataset.from_dict({\n",
    "                'context': nnds['context'],\n",
    "                'question': nnds['question'],\n",
    "                'answers': nnds['answers'],\n",
    "                'answers_generated': list(chain(*predictions))\n",
    "            })"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
