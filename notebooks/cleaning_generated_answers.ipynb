{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abfd0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7437361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"brimmann2/squad-v2-sampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34c07c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['gem_id', 'id', 'title', 'context', 'question', 'target', 'references', 'answers', 'embeddings', 'generated_text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['gem_id', 'id', 'title', 'context', 'question', 'target', 'references', 'answers', 'embeddings', 'generated_text'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['gem_id', 'id', 'title', 'context', 'question', 'target', 'references', 'answers', 'embeddings', 'generated_text'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da9ec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding rows with '<xRAG>' ---\n",
      "Found 41 rows with '<xRAG>' in the 'train' split.\n",
      "Found 12 rows with '<xRAG>' in the 'test' split.\n",
      "Found 9 rows with '<xRAG>' in the 'validation' split.\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DatasetDict is named dataset_dict\n",
    "\n",
    "print(\"--- Finding rows with '<xRAG>' ---\")\n",
    "for split in ds:\n",
    "    rows_with_xrag = ds[split].filter(\n",
    "        lambda example: '<xRAG>' in example['generated_text']\n",
    "    )\n",
    "    print(f\"Found {len(rows_with_xrag)} rows with '<xRAG>' in the '{split}' split.\")\n",
    "    \n",
    "    # You can uncomment the following lines to inspect an example\n",
    "    # if len(rows_with_xrag) > 0:\n",
    "    #     print(\"Example text:\")\n",
    "    #     print(rows_with_xrag[0]['generated_text'])\n",
    "    #     print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fa375f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Finished removing '<xRAG>' ---\n"
     ]
    }
   ],
   "source": [
    "# Define a function to remove the tag\n",
    "def remove_xrag_tag(example):\n",
    "    # .replace() will remove all occurrences of the substring\n",
    "    example['generated_text'] = example['generated_text'].replace('<xRAG>', '')\n",
    "    return example\n",
    "\n",
    "# Apply the function to the whole dataset\n",
    "cleaned_dataset_dict = ds.map(remove_xrag_tag)\n",
    "\n",
    "print(\"\\n--- Finished removing '<xRAG>' ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8bca785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying the changes ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1afcfbd54a3429aafb3d362abae5982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 rows with '<xRAG>' in the cleaned 'train' split.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3e144820984d1b91a1d42bbbbbbc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576de4436dc44f70a7e4a8a44835d5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Before cleaning ---\n",
      "- The aircraft is not able to take off from a short runway.\n",
      "- The aircraft is not able to land on a short runway.\n",
      "- The aircraft is not able to take off from a runway with a high <xRAG> slope.\n",
      "- The aircraft is not able to land on a runway with a high slope.\n",
      "- The aircraft is not able to take off from a runway with a high headwind.\n",
      "- The aircraft is not able to land on a runway with a high headwind.\n",
      "- The aircraft is not able to take off from a runway with a high tailwind.\n",
      "- The aircraft is not able to land on a runway with a high tailwind.\n",
      "- The aircraft is not able to take off from a runway with a high crosswind.\n",
      "- The aircraft is not able to land on a runway with a high crosswind.\n",
      "- The aircraft is not able to take off from a runway with\n",
      "\n",
      "--- After cleaning ---\n",
      "- The aircraft is not able to take off from a short runway.\n",
      "- The aircraft is not able to land on a short runway.\n",
      "- The aircraft is not able to take off from a runway with a high  slope.\n",
      "- The aircraft is not able to land on a runway with a high slope.\n",
      "- The aircraft is not able to take off from a runway with a high headwind.\n",
      "- The aircraft is not able to land on a runway with a high headwind.\n",
      "- The aircraft is not able to take off from a runway with a high tailwind.\n",
      "- The aircraft is not able to land on a runway with a high tailwind.\n",
      "- The aircraft is not able to take off from a runway with a high crosswind.\n",
      "- The aircraft is not able to land on a runway with a high crosswind.\n",
      "- The aircraft is not able to take off from a runway with\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Verifying the changes ---\")\n",
    "# Check the 'train' split of the new, cleaned dataset\n",
    "rows_after_cleaning = cleaned_dataset_dict['train'].filter(\n",
    "    lambda example: '<xRAG>' in example['generated_text']\n",
    ")\n",
    "\n",
    "print(f\"Found {len(rows_after_cleaning)} rows with '<xRAG>' in the cleaned 'train' split.\")\n",
    "# This should output 0.\n",
    "\n",
    "# You can also compare an original example with its cleaned version\n",
    "try:\n",
    "    # Find an example that originally had the tag\n",
    "    original_example = ds['train'].filter(lambda ex: '<xRAG>' in ex['generated_text'])[0]\n",
    "    \n",
    "    # Find the same example in the cleaned dataset using its 'id'\n",
    "    example_id = original_example['id']\n",
    "    cleaned_example = cleaned_dataset_dict['train'].filter(lambda ex: ex['id'] == example_id)[0]\n",
    "\n",
    "    print(\"\\n--- Before cleaning ---\")\n",
    "    print(original_example['generated_text'])\n",
    "\n",
    "    print(\"\\n--- After cleaning ---\")\n",
    "    print(cleaned_example['generated_text'])\n",
    "except IndexError:\n",
    "    print(\"\\nNo examples with '<xRAG>' found in the original 'train' split to compare.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce53928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying the entire cleaned dataset ---\n",
      "Verifying split: 'train'...\n",
      "-> Verification successful for 'train'. No '<xRAG>' tags found.\n",
      "Verifying split: 'test'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f701ebceee442d980c9b90c5b17a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Verification successful for 'test'. No '<xRAG>' tags found.\n",
      "Verifying split: 'validation'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571622065c1d4be0ab9d273ded08cc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Verification successful for 'validation'. No '<xRAG>' tags found.\n",
      "\n",
      "âœ… Verification complete. All splits are clean.\n"
     ]
    }
   ],
   "source": [
    "# Assuming cleaned_dataset_dict is your dataset after running the map function\n",
    "\n",
    "print(\"\\n--- Verifying the entire cleaned dataset ---\")\n",
    "\n",
    "for split_name, dataset_split in cleaned_dataset_dict.items():\n",
    "    print(f\"Verifying split: '{split_name}'...\")\n",
    "    \n",
    "    # Filter the split to find any remaining instances\n",
    "    rows_with_xrag = dataset_split.filter(\n",
    "        lambda example: '<xRAG>' in example['generated_text']\n",
    "    )\n",
    "    \n",
    "    # Assert that the count of such rows is zero\n",
    "    count = len(rows_with_xrag)\n",
    "    assert count == 0, f\"Found {count} rows with '<xRAG>' in the '{split_name}' split after cleaning!\"\n",
    "    \n",
    "    print(f\"-> Verification successful for '{split_name}'. No '<xRAG>' tags found.\")\n",
    "\n",
    "print(\"\\nâœ… Verification complete. All splits are clean.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fff89b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377f4c2f0f924c1aafe24d59172f78be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c0a5f36dc8446cbdfaea2854022e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc515f874844a61aaf324c2b12ce334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bb19d054e5458ebb35f2409964e33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b01a8e359244b7989610ac595505ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e36d68dc8f4f4694dd75c33c8451ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb07ff77740475dbdda29d973b02f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d4683d0669480c9be77efa6479f2d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cb2e443f84400fa2fad60debf6cb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125b3edd1a09414cbde58c30bd27d90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6447c7a2cb455b95e318462b951f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d914ef577a94df39a164fd60a432ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/brimmann2/squad-v2-sampled/commit/c18493ce0910dbf81b2925c4a6f5209e0846ad6d', commit_message='Upload dataset', commit_description='', oid='c18493ce0910dbf81b2925c4a6f5209e0846ad6d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/brimmann2/squad-v2-sampled', endpoint='https://huggingface.co', repo_type='dataset', repo_id='brimmann2/squad-v2-sampled'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset_dict.push_to_hub(\"brimmann2/squad-v2-sampled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
