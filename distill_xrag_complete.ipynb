{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.train_utils import train\n",
    "from configs.configs_utils import update_config\n",
    "from data.data_utils import (get_dataloader, get_distillation_dataloader)\n",
    "from train.tools import (setup, setup_environ_flags, clear_gpu_cache)\n",
    "from models.models_utils import  get_optimizer\n",
    "from models.xrag_models_utils import get_xrag_models\n",
    "from data.data_utils import get_dataloader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.datasets import dataset as DatasetConfig\n",
    "from configs.training import train_config as TrainConfig\n",
    "from configs.distillation import distillation_config as DistillationConfig\n",
    "from configs.fsdp import fsdp_config as FsdpConfig\n",
    "\n",
    "dataset_config = DatasetConfig()\n",
    "train_config = TrainConfig()\n",
    "distill_config = DistillationConfig()\n",
    "fsdp_config = DistillationConfig()\n",
    "train_config.model_name = \"google/gemma-3-1b-it\"\n",
    "distill_config.model_name = \"Hannibal046/xrag-7b\"\n",
    "train_config.batch_size_training = 4\n",
    "train_config.distillation = True\n",
    "train_config.num_workers_dataloader = 0\n",
    "dataset_config.file = \"data/loaders/squad-v2-sampled.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb234b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8de644",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_tokenizer, teacher_tokenizer, model = get_xrag_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c26c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_train_dataloader, teacher_eval_dataloader = get_dataloader(dataset_config, train_config, teacher_tokenizer, rank, distill_config)\n",
    "student_train_dataloader, student_eval_dataloader = get_dataloader(dataset_config, train_config, student_tokenizer, rank, distill_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(model, train_config, fsdp_config)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=train_config.lr, epochs=train_config.num_epochs, steps_per_epoch=len(student_train_dataloader),\n",
    "                                                pct_start=train_config.pct_start, div_factor=train_config.div_factor, final_div_factor=train_config.final_div_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(\n",
    "      model,\n",
    "      student_train_dataloader,\n",
    "      student_eval_dataloader,\n",
    "      optimizer,\n",
    "      scheduler,\n",
    "      train_config.gradient_accumulation_steps,\n",
    "      train_config,\n",
    "      distill_config,\n",
    "      dataset_config,\n",
    "      teacher_train_dataloader if train_config.distillation else None,\n",
    "      teacher_eval_dataloader if train_config.distillation else None,\n",
    "      fsdp_config if train_config.enable_fsdp else None,\n",
    "      None,\n",
    "      rank,\n",
    "  )\n",
    "if rank == 0:\n",
    "    [print(f'Key: {k}, Value: {v}') for k, v in results.items()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
