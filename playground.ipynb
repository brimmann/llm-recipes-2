{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55de7127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llm-recipes-2'...\n",
      "remote: Enumerating objects: 116, done.\u001b[K\n",
      "remote: Counting objects: 100% (116/116), done.\u001b[K6)\u001b[K\n",
      "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
      "remote: Total 116 (delta 42), reused 102 (delta 28), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (116/116), 311.20 KiB | 712.00 KiB/s, done.\n",
      "Resolving deltas: 100% (42/42), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/brimmann/llm-recipes-2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e58af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/llm-recipes-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4accd73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brimmann/works/llm-recipes-2/.venv/lib/python3.9/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/brimmann/works/llm-recipes-2/.venv/lib/python3.9/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/brimmann/works/llm-recipes-2/models/tools.py:5: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging\n"
     ]
    }
   ],
   "source": [
    "from train.train_utils import train\n",
    "from configs.configs_utils import update_config\n",
    "from data.data_utils import (get_dataloader, get_distillation_dataloader)\n",
    "from train.tools import (setup, setup_environ_flags, clear_gpu_cache)\n",
    "from models.models_utils import  get_optimizer\n",
    "from models.models_utils import get_distillation_models\n",
    "from data.data_utils import get_dataloader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa59de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.datasets import dataset as DatasetConfig\n",
    "from configs.training import train_config as TrainConfig\n",
    "from configs.distillation import distillation_config as DistillationConfig\n",
    "from configs.fsdp import fsdp_config as FsdpConfig\n",
    "\n",
    "dataset_config = DatasetConfig()\n",
    "train_config = TrainConfig()\n",
    "distill_config = DistillationConfig()\n",
    "fsdp_config = DistillationConfig()\n",
    "train_config.model_name = \"google/gemma-3-1b-it\"\n",
    "distill_config.model_name = \"Hannibal046/xrag-7b\"\n",
    "train_config.batch_size_training = 8\n",
    "train_config.distillation = True\n",
    "train_config.num_workers_dataloader = 0\n",
    "train_config.num_epochs = 5\n",
    "dataset_config.file = \"data/loaders/squad-v2-sampled.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bc1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23682285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d871e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Model google/gemma-3-1b-it\n",
      "\n",
      "--> google/gemma-3-1b-it has 999.885952 Million params\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212fb5b196b141afb0a106c134f8918a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "student_tokenizer, teacher_tokenizer, model = get_distillation_models(train_config, distill_config, fsdp_config, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cbe811",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_train_dataloader, teacher_eval_dataloader = get_dataloader(dataset_config, train_config, teacher_tokenizer, rank, distill_config)\n",
    "student_train_dataloader, student_eval_dataloader = get_dataloader(dataset_config, train_config, student_tokenizer, rank, distill_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677513b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(model, train_config, fsdp_config)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=train_config.lr, epochs=train_config.num_epochs, steps_per_epoch=len(student_train_dataloader),\n",
    "                                                pct_start=train_config.pct_start, div_factor=train_config.div_factor, final_div_factor=train_config.final_div_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(\n",
    "      model,\n",
    "      student_train_dataloader,\n",
    "      student_eval_dataloader,\n",
    "      optimizer,\n",
    "      scheduler,\n",
    "      train_config.gradient_accumulation_steps,\n",
    "      train_config,\n",
    "      distill_config,\n",
    "      dataset_config,\n",
    "      teacher_train_dataloader if train_config.distillation else None,\n",
    "      teacher_eval_dataloader if train_config.distillation else None,\n",
    "      fsdp_config if train_config.enable_fsdp else None,\n",
    "      None,\n",
    "      rank,\n",
    "  )\n",
    "if rank == 0:\n",
    "    [print(f'Key: {k}, Value: {v}') for k, v in results.items()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
